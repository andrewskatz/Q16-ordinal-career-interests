---
title: "Question 16k - Protect Against Cyber-attacks"
author: "Katz et al."
date: "5/22/2021"
output: html_document
---




```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
library(psych)
library(tidyverse)
library(tidymodels)
library(ranger)
library(purrrlyr)
library(purrr)
library(randomForest)
library(pander)
library(kableExtra)
library(knitr)

library(brms)
library(tidybayes)
library(sjPlot)


library(ordinalForest)

library(rstanarm) #for hierarchical shrinkage prior
library(corrplot)
library(bayesplot)
library(projpred)

```



```{r notebook vars}
analysis_item <- "Q16k"
save_topic <- "cyber"
topic <- "Protect Against Cyber-attacks"
```



Script for creating random forests for Q5 and Q16

```{r}
setwd("G:/My Drive/AK Faculty/Research/Projects/project students and climate change/analysis/q27 clustering")

# climate_data <- read_csv("G:/My Drive/AK Faculty/Research/Projects/project students and climate change/data/updated_climate_df_2.csv")


#original data set
#climate_data <- read_csv("G:/My Drive/AK Faculty/Research/Projects/project students and climate change/data/climate_data.csv")

# read in the imputed dataset

# climate_imp_long_full <- read_csv("climate_imp_long_40_full_inf_cl_hdb_agg_20210518.csv")
climate_imp_long_full <- read_csv("climate_imputed_40_lpa_cl12_2022-08-10.csv")
```


```{r}
# imp_number <- 1
#imp_number <- 2
#imp_number <- 3
#imp_number <- 4
# imp_number <- 5
max_imp_num <- 5
max_imp_num <- 2 # trying this to see if it fixes the cv_varsel issue of taking way too long to run
climate_data <- climate_imp_long_full %>% filter(.imp <= max_imp_num)



```






## Create a new dataframe for the random forest work

### Perform EFA for Q28

```{r}



Q28_vars <- paste0("Q28", letters[1:12])


Q28_df <- climate_data %>% drop_na(Q28_vars) %>% select(Q28_vars)

Q28_fa <- fa(Q28_df, nfactors = 2, fm = "ml", rotate = "oblimin")
print(Q28_fa, cut = 0.3, digits = 3)
# use `print(fa, digits = 3)` to view FLs < .3

```

Calculate Cronbach's alpha for internal consistency reliability

```{r}


FA1 <- c("Q28a", "Q28f", "Q28g", "Q28h", "Q28i", "Q28k")
FA2 <- c("Q28c", "Q28d", "Q28e", "Q28j", "Q28l")

alpha.fa1 <- psych::alpha(Q28_df[FA1])
print(alpha.fa1, digits = 3) #0.91

alpha.fa2 <- psych::alpha(Q28_df[FA2])
print(alpha.fa2, digits = 3) #0.80


```



Add variables for Q28_tech_norm ((Q28a + Q28f + Q28g + Q28h + Q28i + Q28k) / 6) and Q28_social_norm ((Q28c + Q28d + Q28e + Q28j + Q28l) / 5)
```{r}

climate_data <- climate_data %>% 
  mutate(Q28_social = Q28c + Q28d + Q28e + Q28j + Q28l,
         Q28_tech = Q28a + Q28f + Q28g + Q28h + Q28i + Q28k,
         Q28_social_norm = Q28_social / 5,
         Q28_tech_norm = Q28_tech / 6)

```


Perform EFA for Q12

```{r}
Q12_vars <- paste0("Q12", letters[1:9])

Q12_df <- climate_data %>% drop_na(Q12_vars) %>% select(Q12_vars)

Q12_fa <- fa(Q12_df, nfactors = 2, fm = "ml", rotate = "oblimin")
print(Q12_fa, cut = 0.3, digits = 3)

```


```{r}

FA1 <- c("Q12a", "Q12b", "Q12c")
FA2 <- c("Q12d", "Q12e", "Q12f", "Q12g", "Q12h", "Q12i")

alpha.fa1 <- psych::alpha(Q12_df[FA1])
print(alpha.fa1, digits = 3) #0.83

alpha.fa2 <- psych::alpha(Q12_df[FA2])
print(alpha.fa2, digits = 3) #0.90

```



Add variables for Q12 factors (Q12abc_norm (a+b+c)/3 and Q12_defghi_norm = (d+e+f+g+h+i)/6)

```{r}

climate_data <- climate_data %>% 
  mutate(Q12abc = Q12a + Q12b + Q12c,
         Q12defghi = Q12d + Q12e + Q12f + Q12g + Q12h + Q12i,
         Q12abc_norm = Q12abc / 3,
         Q12defghi_norm = Q12defghi / 6)

```





### Recode variables
```{r}

climate_data <- climate_data %>% 
  mutate(major = case_when(Q29 == 1 ~ "Aer/Oce",
                           Q29 == 2 ~ "Agr/Biol",
                           Q29 == 3 ~ "Bio",
                           Q29 == 4 ~ "Civ",
                           Q29 == 5 ~ "Che",
                           Q29 == 6 ~ "Con",
                           Q29 == 7 ~ "Comp",
                           Q29 == 8 ~ "Ele",
                           Q29 == 9 ~ "EngPhy",
                           Q29 == 10 ~ "Env/Eco",
                           Q29 == 11 ~ "Ind",
                           Q29 == 12 ~ "Mat",
                           Q29 == 13 ~ "Mec",
                           Q29 == 14 ~ "Min",
                           Q29 == 15 ~ "Nuc",
                           Q29 == 16 ~ "Softw",
                           Q29 == 17 ~ "Str/Arc",
                           Q29 == 18 ~ "Gen"))

```



Remove majors with fewer than 30 students and students with NA for major


```{r}


climate_data %>% count(Q29, sort = TRUE)
climate_data %>% count(major, sort = TRUE)
cutoff <- 30

climate_data <- climate_data %>% 
  add_count(Q29, name = "major_count") %>% 
  filter(major_count > cutoff) %>% 
  filter(!is.na(Q29))

climate_data %>% count(Q29, sort = TRUE)

```

### Filling in 0s
Fill in Q1, Q3, Q5, Q7, Q39 NAs with 0's (the way they were coded, it's ambiguous if an NA is there intentionally by the participant, so this is a conservative assumption to make that an NA actually corresponds to an intentional omission rather than an accidental omission)

```{r}
# there is a problem with Q7 vars because some are read in as character columns
climate_data %>% select(Q7a:Q7v)

```



```{r}
# prepraing the data
# start with the climate_data dataframe


Q1_vars <- paste0("Q1", letters[1:20])
Q3_vars <- paste0("Q3", letters[1:7])
Q5_vars <- paste0("Q5", letters[1:10])

Q35_vars <- paste0("Q35", letters[1:9])
Q39_vars <- paste0("Q39", letters[1:9])

Q7_vars <- paste0("Q7", letters[1:22])
Q7tally_vars <- paste0("Q7", letters[1:22], "_tally")
```


```{r}
#str(climate_data)

### old way to remove disciplines with 
# rf_df <- climate_data %>% 
#   filter(!is.na(Q29)) %>% 
#   filter(Q29 != 15) %>% 
#   filter(Q29 != 14) %>% 
#   filter(Q29 != 9) %>% 
#   filter(Q29 != 2)

rf_df <- climate_data

# rf_df %>% group_by(Q29) %>% count()

#rf_df[, Q1_vars]
rf_df <- rf_df %>% mutate_at(vars(Q1_vars), ~replace_na(., 0))
#rf_df[, Q1_vars]

#rf_df[, Q3_vars]
rf_df <- rf_df %>% mutate_at(vars(Q3_vars), ~ replace_na(.,0))
#rf_df[, Q3_vars]

#rf_df[,Q5_vars]

#rf_df[, Q7_vars]
#rf_df <- rf_df %>% mutate_at(vars(Q7_vars), ~ replace_na(., 0))
#rf_df[,Q7_vars]

#rf_df[, Q35_vars]
rf_df <- rf_df %>% mutate_at(vars(Q35_vars), ~ replace_na(., 0))
#rf_df[,Q35_vars]

#rf_df[, Q39_vars]
rf_df <- rf_df %>% mutate_at(vars(Q39_vars), ~ replace_na(., 0))
#rf_df[,Q39_vars]
```

### Dropping items
Drop individual Q12, Q16, and Q28 items. Q16 items were too similar to Q5 items and Q28 items were factored

```{r}
Q2_vars <- paste0("Q2", letters[1:7])
Q12_vars <- paste0("Q12", letters[1:9])
Q16_vars <- paste0("Q16", letters[1:13])

Q27_vars <- paste0("Q27", letters[1:9])
Q27_tri_num_vars <- paste0(Q27_vars, "_tri_num")

Q28_vars <- paste0("Q28", letters[1:12])
```


```{r}
train_df <- rf_df %>% 
  dplyr::select(-Q28_tech, -Q28_social, -Q12abc, -Q12defghi)

train_df <- train_df %>% dplyr::select(-Q1_vars)

train_df <- train_df %>% dplyr::select(-Q12_vars)

# remove q27 vars because they repeat information in class_time_rank
train_df <- train_df %>% dplyr::select(-Q27_vars)
train_df <- train_df %>% dplyr::select(-Q27_tri_num_vars)

train_df <- train_df %>% dplyr::select(-Q28_vars)

```






Remove additional columns that will not feed into the random forest algorithm



```{r}
# remove columns with majority na (noticed from visual inspection)
removal_vars <- c("School", "Litho", 
                  "Q7_disc_spec_env_sum", 
                  "Q7_disc_spec_env_sum", 
                  "env_tally_sum",
                  "Q29", "Q30",
                  "Q31", "Q32", 
                  "Q33","Q33_", 
                  "Q34", 
                  # "Q36a", "Q36b", 
                  "Q37_", "Q37",
                  "Q38", Q39_vars,
                  "Q38_", "Q39_", "Q40",
                  "abe", "Q16kbc", "lm", "dfg", "hijk",
                  "spec", "other", "tally", "ele", "Q16_bin", "_ind")



# Q13, Q14 were originally on the removal list - not sure why - need to add back in
# drop Q7 except for the wt_sum
# consider removing "sum" from the above

removal_vars_start <- paste0("^(", paste(removal_vars, collapse="|"), ")")
removal_vars_end <- paste0("(", paste(removal_vars, collapse="|"), ")$")


# create a dataframe called train_df that we'll use for training the random forests
train_df <- train_df %>% dplyr::select(-matches(removal_vars_start))
train_df <- train_df %>% dplyr::select(-matches(removal_vars_end))
```




```{r}
# remove the original Q7 vars because they were too messy - use tallies instead

# remove other Q5 variables aside from 5e
## probably want to change this to Q16 removals

forest_outcome_var <- analysis_item
```


```{r}
Q2_removals <- Q2_vars[Q2_vars != forest_outcome_var]

train_df <- train_df %>% dplyr::select(-Q2_removals)
```


```{r}
Q16_removals <- Q16_vars[Q16_vars != forest_outcome_var]


train_df <- train_df %>% dplyr::select(-Q7_vars)
train_df <- train_df %>% dplyr::select(-Q5_vars) # drop Q5 vars for Q16 training
train_df <- train_df %>% dplyr::select(-Q16_removals)
#train_df <- train_df %>% dplyr::select(-Q16_energy)
```


```{r}
factor_vars <- c("major", "poli_aff", "gender", "race_eth", "religion_aff")

train_df <- train_df %>% 
  mutate_at(factor_vars, as.factor)
  
  # mutate(Q29 = as.factor(Q29),
  #        Q37 = as.factor(Q37))


```






# Create the random forest model fit

remove IPEDS vars

```{r}

# just to get ipeds_vars
data_path <- "G:/My Drive/AK Faculty/Research/Projects/project students and climate change/data/"
file_name <- "ipeds_inst_char_2018.csv"

school_info <- read_csv(paste0(data_path, file_name))

ipeds_vars <- names(school_info)
rm(school_info)

```



```{r}
train_df <- train_df %>% 
  select(-one_of(ipeds_vars))
```



```{r}
extra_removal_vars <- c(".id", "student_id",
                        "full_hdb_cluster", "full_agg_cluster",
                        "cluster_time_rank_hdb", "cluster_avg_hdb",
                        "cluster_avg_agg", "cluster",
                        "class_avg", "Class", "cluster_time_rank", 
                        "cluster_avg", "cluster_time_rank_rev",
                        "dim1", "dim2", "major_count",
                        "gpa", "IALIAS", 
                        "DUNS", "VETURL", "ATHURL", 
                        "STABBR_student", "latitude",
                        "longitude",
                        "state_name", "region_name", "region_code",
                        "division_name", "division_code")

train_df <- train_df %>% 
  select(-one_of(extra_removal_vars))
```




## Option 1: Regression forest

```{r}

# set.seed(42)
# 
# 
# rf_mod <- randomForest(formula = Q16k ~ ., 
#                        data = train_df,
#                        ntree = 1000,
#                        proximity = TRUE,
#                        na.action = na.roughfix,
#                        importance = TRUE)



```



```{r}

# imp <- importance(rf_mod, type = 1, scale = F) # permutation importances 
#(specifying "type = 1" pulls MeanDecreaseAccuracy instead of MeanDecreaseGini)

```

Manual way of collecting variable importance data

```{r}
plot_type <- "Ordinal Forest Variable Importance"

plot_title <- paste(plot_type, topic, sep = ": ")


#row.names(imp)
# featureImportance <- data.frame(Feature = row.names(imp), Importance = imp[,1])
# 
# p <- featureImportance %>% 
#   top_n(30, Importance) %>% 
#   ggplot(aes(x = reorder(Feature, -Importance), y = Importance)) +
#   geom_bar(stat = "identity", fill = "#53cfff", width = 0.65) +
#   coord_flip() + 
#   theme_light(base_size = 20) +
#   theme(axis.title.x = element_text(size = 10, color = "black"),
#         axis.title.y = element_blank(),
#         axis.text.x  = element_text(size = 10, color = "black"),
#         axis.text.y  = element_text(size = 10, color = "black"),
#         plot.title = element_text(size = 10, hjust = 0.5)) +
#   ggtitle(plot_title)
# 
# p



```




Calculate variable importance and plot using permutation

```{r}
# library(vip)

#code_break


```












## Option 2: Ordinal Forest instead of Regression Random Forest


```{r}
train_df <- train_df %>% 
  mutate(Q16k = as.ordered(Q16k))
```


```{r}


# train_df %>% drop_na(Q32, Q33, Q37)

ord_rf_df <- train_df %>% 
  drop_na(poli_aff, race_eth, gender, religion_aff, Q36a, Q36b)
```





```{r}
set.seed(42)

var_imp_list <- vector(mode = "list", length = max_imp_num)

for (i in seq(1:max_imp_num)){
  # print(i)
  temp_df <- ord_rf_df %>% 
    filter(.imp == i) %>%
    select(-.imp)
  
  temp_df <- as.data.frame(temp_df)
  rf_mod_ord <- ordfor(depvar = analysis_item, 
                     data = temp_df, 
                     perffunction = "proportional")
  
  # save variable importance numbers
  var_imp <- rf_mod_ord$varimp

  # store results in temp_imp_df
  temp_imp_df <- tibble(imp = i,
                        variable = names(var_imp),
                        var_importance = round(var_imp, 10))
  
  # save temp_imp_df in var_imp_list
  var_imp_list[[i]] <- temp_imp_df
  
}

# ord_rf_df %>% select(Q16k)

# ord_rf_df <- as.data.frame(ord_rf_df)
# default mtry
# rf_mod_ord <- ordfor(depvar = "Q16k", 
#                      data = ord_rf_df, 
#                      perffunction = "proportional")




```




#### For only one dataset's random forest
```{r}
# sort(rf_mod_ord$varimp, decreasing=TRUE)

# var_imp <- rf_mod_ord$varimp
# # var_imp
# # names(var_imp)
# 
# var_imp_df <- tibble(variable = names(var_imp),
                     # var_importance = var_imp)
```

Save variable importance df
```{r}
# var_imp_df %>% write_csv(paste0(analysis_item,"_ord_rf_var_imp.csv"))
```

#### For multiple datasets

```{r}

var_imp_comb <- bind_rows(var_imp_list)

var_imp_df <- var_imp_comb %>%
  group_by(variable) %>%
  summarize(var_importance = round(mean(var_importance), 8))

```

```{r}
var_imp_df %>% write_csv(paste0(analysis_item,
                                "_ord_rf_var_imp_avg.csv"))

```



```{r}
# var_imp_df <- read_csv(paste0(analysis_item,"_ord_rf_var_imp.csv"))
var_imp_df <- read_csv(paste0(analysis_item,"_ord_rf_var_imp_avg.csv"))

```

#### Plot RF variable importance 

For ordinal forest variable importance measures

```{r}

plot_type <- "Ordinal Forest Variable Importance"

plot_title <- paste(plot_type, topic, sep = ": ")


p <- var_imp_df %>% 
  top_n(30, var_importance) %>% 
  ggplot(aes(x = reorder(variable, -var_importance), y = var_importance)) +
  geom_bar(stat = "identity", fill = "#53cfff", width = 0.65) +
  coord_flip() + 
  theme_light() +
  labs(x = "Variable",
       y = "Variable Importance") +
  theme(axis.title.x = element_text(size = 10, color = "black"),
        # axis.title.y = element_blank(),
        axis.text.x  = element_text(size = 10, color = "black"),
        axis.text.y  = element_text(size = 10, color = "black"),
        plot.title = element_text(size = 9, hjust = 0.5)) +
  ggtitle(plot_title)

p

```




```{r}

var_imp_df %>% 
  top_n(30, var_importance) %>%
  arrange(-var_importance) %>%
  select(variable)

```



#### Save variable importance figure

```{r}

file_name <- paste("rf_ord_var_imp",
                   analysis_item,
                   save_topic, 
                    Sys.Date(),
                    max_imp_num,
                    "imps.png", sep = "_")
ggsave(filename = file_name,
       plot = p,
       height = 5,
       width = 7,
       units = "in",
       dpi= 600)

```






# Modeling




## Variable Selection


```{r}
var_imp_df <- read_csv(paste0(analysis_item,"_ord_rf_var_imp_avg.csv"))

```



```{r}

top_30_vars <- var_imp_df %>% 
  top_n(30, var_importance) %>%
  arrange(-var_importance) %>%
  select(variable)

top_30_vars

         
```



```{r}
as.vector(top_30_vars['variable'])
paste0(top_30_vars['variable'])

predictor_vector <- pull(top_30_vars, variable)

terms_sum <- paste(predictor_vector, collapse = " + ")
terms_sum
```

Check to make sure all are dbl or fct variables

```{r}
train_df %>% select(all_of(predictor_vector))

```

Recode poli_aff

```{r}

train_df <- train_df %>%
  mutate(poli_aff = as_factor(poli_aff),
         gender = as_factor(gender))

```



```{r}
target <- analysis_item
```


```{r}
formula <- paste(c(target, terms_sum), collapse = " ~ ")
formula

```


```{r}

# corrplot(cor(climate_data[, c(target,predictor_vector)]))

```


```{r}
n <- nrow(train_df)
p <- length(predictor_vector)
p0 <- 6 # prior guess for the number of relevant variables
tau0 <- p0/(p-p0) * 1/sqrt(n)
rhs_prior <- set_prior(horseshoe(scale_global=tau0))

```


```{r}
train_df_unordered <- train_df %>% 
  mutate(Q16k = as.double(Q16k))

train_df_unordered %>%
  select(Q16k)

```



```{r}
seed <- 1234


fitrhs <- brm(formula, 
              data = train_df_unordered, 
              prior = rhs_prior,
              cores = parallel::detectCores())

```



```{r}
summary(fitrhs)
```


```{r}
train_df_unordered %>% drop_na(all_of(predictor_vector))

y <- pull(train_df_unordered %>% drop_na(all_of(predictor_vector)), target)
#y
```



```{r}

yrep <- posterior_predict(fitrhs, draws = 50)
ppc_dens_overlay(y, yrep)

```



```{r}

fitrhs_cvvs <- cv_varsel(fitrhs, 
                         method = 'forward', 
                         cv_method = 'loo',
                         nloo = n, verbose = FALSE)

```



```{r}

vs_plot <- plot(fitrhs_cvvs, stats = c('elpd', 'rmse'), deltas=FALSE)

vs_plot
```

#### save vs plot

```{r}

file_name <- paste(analysis_item,
                   "vs_plot",
                    Sys.Date(),
                    ".png", sep = "_")

ggsave(filename = file_name,
  plot = vs_plot,
  width = 7,
  height = 5,
  units = "in",
  dpi = 600)

```






```{r}
nsel <- 10 #set manually by looking at plot above
(nsel <- projpred::suggest_size(fitrhs_cvvs, alpha=0.1))


```


```{r}

(vsel <- projpred::solution_terms(fitrhs_cvvs)[1:nsel])


```


Form projected posterior for the selected model

```{r}

projrhs <- projpred::project(fitrhs_cvvs, nv = nsel, ns = 4000)

parnames(fitrhs)

```


Plot marginals of projected posterior


```{r}

parnames_tib <- tibble(parname = parnames(fitrhs))
fixed_vsel <- parnames_tib %>% 
  filter(str_detect(parname, "b_")) %>%
  mutate(parname = str_remove(parname, "b_")) %>%
  filter(parname != "Intercept")

fixed_vsel
fixed_vsel <- pull(fixed_vsel, parname)
fixed_vsel
```


```{r}
colpars <- colnames(as.matrix(projrhs))
colpars <- colpars[colpars != "Intercept"]
colpars <- colpars[colpars != "sigma"]

# vsel

# colnames(as.matrix(projrhs))

mcmc_areas(as.matrix(projrhs), 
           pars = colpars)
# need to use fixed_vsel to account for some variables that were factors
# mcmc_areas(as.matrix(projrhs), pars = fixed_vsel)



```



### Create ordinal outcome model with most predictive items from projection predictive variable selection


```{r}
terms_sum <- paste(vsel, collapse = " + ")
terms_sum

```



```{r}

target <- analysis_item
ordered_target <- paste0("ordered(", target, ")")

```


```{r}
vs_formula <- paste(c(ordered_target, terms_sum), collapse = " ~ ")
vs_formula
```





#### Create nested data from multiple imputation for modeling

```{r}

climate_data_mod <- climate_imp_long_full %>%
  filter(.imp < 10)


train_df <- climate_data_mod %>% 
  mutate(major = case_when(Q29 == 1 ~ "Aer/Oce",
                           Q29 == 2 ~ "Agr/Biol",
                           Q29 == 3 ~ "Bio",
                           Q29 == 4 ~ "Civ",
                           Q29 == 5 ~ "Che",
                           Q29 == 6 ~ "Con",
                           Q29 == 7 ~ "Comp",
                           Q29 == 8 ~ "Ele",
                           Q29 == 9 ~ "EngPhy",
                           Q29 == 10 ~ "Env/Eco",
                           Q29 == 11 ~ "Ind",
                           Q29 == 12 ~ "Mat",
                           Q29 == 13 ~ "Mec",
                           Q29 == 14 ~ "Min",
                           Q29 == 15 ~ "Nuc",
                           Q29 == 16 ~ "Softw",
                           Q29 == 17 ~ "Str/Arc",
                           Q29 == 18 ~ "Gen"),
         major = as_factor(major),
         Q16k = as.ordered(Q16k))

```


```{r}


str(train_df$major)

# set reference discipline

train_df$major <- fct_relevel(train_df$major, "Mec") 

str(train_df$major)

```

```{r}
train_df_nested <- train_df %>% nest(data = !.imp) 




```




#### Single dataset version

Use single dataset when iterating and MI for final manuscript analysis

```{r}

# mod1_ord_Q16k_vs <- brm(formula = vs_formula,
#                      data = train_df,
#                      family = cumulative("logit"),
#                      # prior = priors1,
#                      cores = parallel::detectCores())

```


#### MI version

```{r}

mod1_ord_Q16k_vs <- brm_multiple(formula = vs_formula,
                     data = train_df_nested$data,
                     family = cumulative("logit"),
                     # prior = priors1,
                     cores = parallel::detectCores())

```








### Check model output


```{r}

# path <- "G:/My Drive/AK Faculty/Research/Projects/project students and climate change/analysis/career interests/question_2/"

# file_name <- "mod1_ord_Q16k_vs.rds"
file_name <- "mod1_ord_Q16k_mi_vs.rds"

mod1_ord_Q16k_vs %>% write_rds(file = file_name)

```


```{r}

mod1_ord_Q16k_vs <- read_rds("mod1_ord_Q16k_mi_vs.rds")

```





```{r}

tab_model(mod1_ord_Q16k_vs)

```



```{r}
summary(mod1_ord_Q16k_vs)
```

```{r}

loo(mod1_ord_Q16k_vs)

```



```{r}
# coef(mod1_ord_Q16k)
fixef(mod1_ord_Q16k_vs)

```

```{r}
get_variables(mod1_ord_Q16k_vs)


```


```{r}

mod_param_vars <- tibble(var = get_variables(mod1_ord_Q16k_vs))
mod_param_vars <- mod_param_vars %>%
  filter(str_detect(var, "b_")) %>%
  filter(!str_detect(var, "Intercept"))

mod_param_vars <- pull(mod_param_vars, var)
mod_param_vars
```



```{r}
stanplot(mod1_ord_Q16k_vs, pars = c("^r_", "^b_", "^sd_")) +
  theme_light() +
  theme(axis.text.y = element_text(hjust = 0))
```


```{r}
plot_type <- "Parameter Estimates"

plot_title <- paste(plot_type, topic, sep = ": ")


mod1_ord_Q16k_vs %>%
  spread_draws(`b_.*`[i], regex = TRUE) %>%
  ggplot(aes(y = factor(i), x = b_Intercept)) +
  stat_halfeye(.width = c(.9, .5)) +
  labs(title = plot_title,
       x = "Parameter Estimate",
       y = "Cluster cutoff point") +
  theme(plot.title = element_text(hjust=0.5))

```

```{r}
mod_param_vars
```


```{r}
plot_type <- "Parameter Density Estimates for Ordinal Regression"

plot_title <- paste(plot_type, topic, sep = ": ")

# need to rename parameters for figure for manuscript
param_plot <- mod1_ord_Q16k_vs %>%
  spread_draws(`b_.*`, regex = TRUE) %>%
  pivot_longer(cols = all_of(mod_param_vars), names_to = "parameter", values_to = "parameter_estimate") %>%
  ggplot(aes(y = factor(parameter), x = parameter_estimate)) +
  geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
  stat_halfeye(.width = c(.9, .5)) +
  labs(title = plot_title,
       x = "Parameter Estimate",
       y = "Survey Item") +
  theme_light() +
  theme(plot.title = element_text(hjust=0.5, size = 9)) +
  xlim(c(-1, 1))


param_plot

```

```{r}

#questions plot
plot_type <- "Parameter Density Estimates for Ordinal Regression"

plot_title <- paste(plot_type, topic, sep = ": ")

# This plot is deprecated because now using alternative method to get all items identified via projection predictive variable selection

# param_plot_q <- mod1_ord_Q16k_vs %>%
#   spread_draws(`b_.*`, regex = TRUE) %>%
#   pivot_longer(cols = starts_with("b_Q"), names_to = "parameter", values_to = "parameter_estimate") %>% 
#   ggplot(aes(y = factor(parameter), x = parameter_estimate)) +
#   geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
#   stat_halfeye(.width = c(.9, .5)) +
#   labs(title = plot_title,
#        x = "Parameter Estimate",
#        y = "Survey Item") +
#   theme_light() +
#   theme(plot.title = element_text(hjust=0.5, size = 9)) +
#   xlim(-1, 1)
# 
# 
# param_plot_q


```







```{r}
plot_type <- "halfeye"
file_name <- paste("manu_rf",
                   analysis_item,
                   save_topic,
                   plot_type,
                   Sys.Date(),
                    ".png",
                   sep = "_")


ggsave(
  filename = file_name,
  plot = param_plot,
  width = 7,
  height = 5,
  units = "in",
  dpi = 600
)

```



```{r}
file_name <- paste(analysis_item,
                   save_topic,
                   plot_type,
                   Sys.Date(),
                   ".png",
                   sep = "_")
# ggsave(
#   filename = "Q16k_infra_halfeye_Qs_20220930.png",
#   plot = param_plot_q,
#   width = 7,
#   height = 5,
#   units = "in",
#   dpi = 600
# )

```




```{r}
# major not identified for this plot

# mod1_ord_Q16k_vs %>%
#   spread_draws(r_major[major,i]) %>%
#   ggplot(aes(y = factor(major), x = r_major)) +
#   stat_halfeye(.width = c(.9, .5)) +
#   facet_grid(major ~ i, scales = "free") +
#   labs(title = "Intercept Estimates for Ordinal Regression with Minimizing Energy Consumption Interest",
#        x = "Parameter Estimate",
#        y = "Cluster cutoff point") +
#   theme(plot.title = element_text(hjust=0.5))


```

### Model checking


```{r}
plot_type <- "Posterior Predictive Check"

plot_title <- paste(plot_type, topic, sep = ": ")

pp_plot_ecdf_vs <- pp_check(mod1_ord_Q16k_vs, type = "ecdf_overlay", nsamples = 100)+
  xlab("Response") + 
  ylab("Cumulative Probability") +
  ggtitle(plot_title)

pp_plot_ecdf_vs


```


```{r}
plot_type <- "pp_ecdf"
file_name <- paste(plot_type,
              analysis_item,
              Sys.Date(),
              ".png", 
              sep = "_")
ggsave(filename = file_name, 
       plot = pp_plot_ecdf_vs, 
       width = 6,
       height = 5,
       units = "in",
       dpi = 600)

```



```{r}
plot_type <- "Posterior Predictive Check"

plot_title <- paste(plot_type, topic, sep = ": ")

pp_plot_bars_vs <- pp_check(mod1_ord_Q16k_vs, type = "bars", nsamples = 500)+
  xlab("Response (1 = Not at all likely, 5 = Extremely likely)") + 
  ylab("Observed Count") +
  ggtitle(plot_title)

pp_plot_bars_vs

```



```{r}
plot_type <- "pp_bars"
file_name <- paste(plot_type,
              analysis_item,
              Sys.Date(),
              ".png", 
              sep = "_")

ggsave(filename = file_name,
       plot = pp_plot_bars_vs, 
       width = 6,
       height = 5,
       units = "in",
       dpi = 600)


```




# Save manuscript figures



```{r}
var_imp_df <- read_csv(paste0(analysis_item, "_ord_rf_var_imp.csv"))

```


For ordinal forest variable importance measures

```{r}
plot_type <- "Ordinal Forest Variable Importance"

plot_title <- paste(plot_type, topic, sep = ": ")


p <- var_imp_df %>%
  filter(!str_detect(variable, "Q16m")) %>%
  top_n(30, var_importance) %>% 
  mutate(variable = case_when(variable == "Q4p" ~ "Career sat.: Volunteering",
                              variable == "Q4c" ~ "Career sat.: Help others",
                              variable == "Q4a" ~ "Career sat.: Make money",
                              variable == "Q4l" ~ "Career sat.: Solve problems",
                              variable == "Q16l" ~ "Career: Advance water tech.",
                              variable == "Q5c" ~ "Career: Poverty and wealth dist.",
                              variable == "Q28_social_norm" ~ "Global warm. as social topic",
                              variable == "Q24k" ~ "Eat less meat",
                              variable == "Q16d" ~ "Career: Sustainability awareness",
                              variable == "Q5i" ~ "Career: Opp. for women/minorities",
                              variable == "Q24j" ~ "Increase public transportation",
                              variable == "Q5j" ~ "Career: Env. degradation",
                              variable == "Q6i" ~ "Int'l travel for service",
                              variable == "Q20d" ~ "Global warming important to me",
                              variable == "Q6d" ~ "Worked in developing country",
                              variable == "Q16g" ~ "Career: Work alongside gov.",
                              variable == "Q18j" ~ "Think of myself as part of nature",
                              variable == "poli_aff" ~ "Political affiliation",
                              variable == "Q16e" ~ "Career: Work on renewable energy",
                              variable == "Q5f" ~ "Career: Water supply",
                              variable == "Q28_tech_norm" ~ "Global warm. as tech. topic",
                              variable == "Q18k" ~ "We should address cli. cha.",
                              variable == "Q18c" ~ "I feel responsible to address env. prob.",
                              variable == "class_time_rank" ~ "Spatiotemporal beliefs",
                              variable == "gender" ~ "Gender",
                              variable == "Q5g" ~ "Career: Food availability",
                              variable == "Q10b" ~ "Engineers make more money",
                              variable == "Q4e" ~ "Career sat: Job security",
                              variable == "Q19d" ~ "Plant and animal rights to exist",
                              variable == "Q6j" ~ "Participated in env. org."
                              )) %>%
  ggplot(aes(x = reorder(variable, -var_importance), y = var_importance)) +
  geom_bar(stat = "identity", fill = "#53cfff", width = 0.65) +
  coord_flip() + 
  theme_light() +
  labs(x = "Variable",
       y = "Variable Importance") +
  theme(axis.title.x = element_text(size = 10, color = "black"),
        # axis.title.y = element_blank(),
        axis.text.x  = element_text(size = 9, color = "black"),
        axis.text.y  = element_text(size = 10, color = "black"),
        plot.title = element_text(size = 10, hjust = 0.5)) +
  ggtitle(plot_title)

p

```




```{r}

var_imp_df %>% 
  top_n(30, var_importance) %>%
  arrange(-var_importance) %>%
  select(variable)

```







## Save variable importance figure

```{r}
file_name <- paste("rf_ord_var_",
                    item,
                    save_topic,
                    Sys.Date(),
                    max_imp_num,
                    "imps.png")
ggsave(filename = file_name,
       plot = p,
       height = 5,
       width = 7,
       units = "in",
       dpi= 600)

```




